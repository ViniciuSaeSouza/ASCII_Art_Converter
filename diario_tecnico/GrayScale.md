In [digital photography](https://en.wikipedia.org/wiki/Digital_photography "Digital photography"), [computer-generated imagery](https://en.wikipedia.org/wiki/Computer-generated_imagery "Computer-generated imagery"), and [colorimetry](https://en.wikipedia.org/wiki/Colorimetry "Colorimetry"), a **greyscale** (more common in [Commonwealth English](https://en.wikipedia.org/wiki/Commonwealth_English "Commonwealth English")) or **grayscale** (more common in [American English](https://en.wikipedia.org/wiki/American_English "American English")) [image](https://en.wikipedia.org/wiki/Image "Image") is one in which ==the value of each [pixel](https://en.wikipedia.org/wiki/Pixel "Pixel") is a single [sample](https://en.wikipedia.org/wiki/Sample_\(signal\) "Sample (signal)") representing only an _amount_ of [light](https://en.wikipedia.org/wiki/Light "Light")==; that is, **it carries only [intensity](https://en.wikipedia.org/wiki/Luminous_intensity "Luminous intensity")** information. Grayscale images, are [black-and-white](https://en.wikipedia.org/wiki/Black-and-white "Black-and-white") or gray [monochrome](https://en.wikipedia.org/wiki/Monochrome "Monochrome"), and composed exclusively of [shades of gray](https://en.wikipedia.org/wiki/Shades_of_gray "Shades of gray"). ==The [contrast](https://en.wikipedia.org/wiki/Contrast_\(vision\) "Contrast (vision)") ranges from [black](https://en.wikipedia.org/wiki/Black "Black") at the weakest intensity to [white](https://en.wikipedia.org/wiki/White "White") at the strongest.==[[1]](https://en.wikipedia.org/wiki/Grayscale#cite_note-1)

In computing, although the grayscale can be computed through [rational numbers](https://en.wikipedia.org/wiki/Rational_numbers "Rational numbers"), image pixels are usually [quantized](https://en.wikipedia.org/wiki/Quantization_\(signal_processing\) "Quantization (signal processing)") to store them as unsigned integers, to reduce the required storage and computation. Some early grayscale monitors can only display up to sixteen different shades, which would be stored in [binary](https://en.wikipedia.org/wiki/Binary_code "Binary code") form using 4 [bits](https://en.wikipedia.org/wiki/Bit "Bit").[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_] But today grayscale images intended for visual display are commonly stored with 8 bits per sampled pixel. This pixel [depth](https://en.wikipedia.org/wiki/Color_depth "Color depth") allows 256 different intensities (i.e., shades of gray) to be recorded, and also simplifies computation as each pixel sample can be accessed individually as one full [byte](https://en.wikipedia.org/wiki/Byte "Byte"). However, if these intensities were spaced equally in proportion to the amount of physical light they represent at that pixel (called a linear encoding or scale), the differences between adjacent dark shades could be quite noticeable as banding [artifacts](https://en.wikipedia.org/wiki/Compression_artifact "Compression artifact"), while many of the lighter shades would be "wasted" by encoding a lot of perceptually-indistinguishable increments. Therefore, the shades are instead typically spread out evenly on a [gamma-compressed nonlinear scale](https://en.wikipedia.org/wiki/Gamma_correction "Gamma correction"), which better approximates uniform perceptual increments for both dark and light shades, usually making these 256 shades enough to avoid noticeable increments.[[2]](https://en.wikipedia.org/wiki/Grayscale#cite_note-2)

---
## Converting color to grayscale

[![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Auschwitz_channel_mixer.jpg/250px-Auschwitz_channel_mixer.jpg)](https://en.wikipedia.org/wiki/File:Auschwitz_channel_mixer.jpg)

> Examples of conversion from a full-color image to grayscale using [Adobe Photoshop](https://en.wikipedia.org/wiki/Adobe_Photoshop "Adobe Photoshop")'s _Channel Mixer_, compared to the original image and colorimetric conversion to grayscale

Conversion of an arbitrary color image to grayscale is not unique in general; different weighting of the color channels effectively represent the effect of shooting black-and-white film with different-colored [photographic filters](https://en.wikipedia.org/wiki/Photographic_filter "Photographic filter") on the cameras.


1. it means that all color channels (R, G, B) where transformed to a single luminescence value (i believe it's called `YLinear`) and replaced each color channel value with `YLinear`. I don't know if/how i should do a gamma compression on the `YLinear` or the result image (the idea of how to save and convert this to a grayscale image it's not yet fully clear on my mind).
2. We can't take a single value of the rgb because an image is composed of three color channel's (Red, Green, Blue) and each channel has it's  weighted relevance on the perception of the image and its luminescence, being that the importance of color for human perception is green, red, blue respectively. So taking only one of the values (or layers of color) from each pixel won't represent the correct value of light.
3. i think we should use the weighted values approach of getting each layer of the R, G, B and summing them with their respective weights and getting the luminescence value (`YLinear`):
   $Ylinear=0.2126Rlinear+0.7152Glinear+0.0722Blinear$
4. I think we should loop through each pixel, get their R,G,B values separately, calculate my $YLinear$ value and then change each channel with the $YLinear$ variable value. i don't really know how i cant then put each pixel on a new image and save that, will have to read the documentation.